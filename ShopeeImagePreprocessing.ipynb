{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ShopeeImagePreprocessing.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNo6tzAyxgJRUyJYDRQ3x5o",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bluezdot/ShopeeImageClassification/blob/main/ShopeeImagePreprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AcUVhXBCJ3CI",
        "outputId": "3e754af9-d4f8-4179-c8dd-538312dca3ff"
      },
      "source": [
        "!git clone https://github.com/bluezdot/ShopeeImageClassification.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'ShopeeImageClassification' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hMRP4FyDKmwI",
        "outputId": "3b194eae-9bdf-40a6-8465-09dacaa2cceb"
      },
      "source": [
        "!pip install albumentations"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: albumentations in /usr/local/lib/python3.7/dist-packages (0.1.12)\n",
            "Requirement already satisfied: imgaug<0.2.7,>=0.2.5 in /usr/local/lib/python3.7/dist-packages (from albumentations) (0.2.6)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from albumentations) (4.1.2.30)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from albumentations) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from albumentations) (1.19.5)\n",
            "Requirement already satisfied: scikit-image>=0.11.0 in /usr/local/lib/python3.7/dist-packages (from imgaug<0.2.7,>=0.2.5->albumentations) (0.18.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from imgaug<0.2.7,>=0.2.5->albumentations) (1.15.0)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (3.2.2)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (1.2.0)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (2021.11.2)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (7.1.2)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (2.4.1)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (2.6.3)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (3.0.6)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (1.3.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qI_rK9yeLY4W",
        "outputId": "831e1374-1f2a-4fc8-e121-23242ee6654f"
      },
      "source": [
        "%cd ShopeeImageClassification/dataset/"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ShopeeImageClassification/dataset\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UwpK1XpUVZUv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 338
        },
        "outputId": "815df365-137e-4428-b598-31e3d01e2dc3"
      },
      "source": [
        "import random\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from torchvision.io import read_image\n",
        "import albumentations as A\n",
        "import albumentations.pytorch\n",
        "from albumentations.pytorch import ToTensorV2"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-778d56f45067>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0malbumentations\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0malbumentations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpytorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0malbumentations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpytorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mToTensorV2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'ToTensorV2' from 'albumentations.pytorch' (/usr/local/lib/python3.7/dist-packages/albumentations/pytorch/__init__.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "scsW5b1de_Sa"
      },
      "source": [
        "train_img_path = './train_images'\n",
        "test_img_path = './test_images'\n",
        "train_df = pd.read_csv('./train.csv')\n",
        "test_df = pd.read_csv('./test.csv')"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nEvQhs_XKHeE"
      },
      "source": [
        "def my_seed(seed):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w5n0OqW_KIQz",
        "outputId": "16669ebf-e891-4df0-b3c2-cda4523f1008"
      },
      "source": [
        "# drop duplicate by p-hash\n",
        "train_df = train_df.drop_duplicates(subset=['image_phash'],keep = 'first')\n",
        "train_df.image_phash.value_counts()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "a16bc292ed094bf6    1\n",
              "bc4a94ed5f2fa480    1\n",
              "ca0e2a7495f1d84f    1\n",
              "ec6bd9b5a74488c8    1\n",
              "dbccc786ce3018c7    1\n",
              "                   ..\n",
              "ed618f98930e784b    1\n",
              "e59a9a659e61329a    1\n",
              "f5e596677098ca24    1\n",
              "bf30e336620f708b    1\n",
              "f876d2c887a986ca    1\n",
              "Name: image_phash, Length: 28735, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pmmr5fOCLMiK",
        "outputId": "5fe10457-bb46-4059-9760-0d9e5a0ad13c"
      },
      "source": [
        "# check if label group preserved\n",
        "train_df.label_group.value_counts()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1141798720    44\n",
              "159351600     43\n",
              "1091404026    39\n",
              "3489985175    37\n",
              "562358068     36\n",
              "              ..\n",
              "370710977      1\n",
              "3601891778     1\n",
              "2067677642     1\n",
              "2213950251     1\n",
              "1332066608     1\n",
              "Name: label_group, Length: 11004, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "wUAsb4ymLqu2",
        "outputId": "df886238-0b8c-48d6-9a52-bc0b41e33cd4"
      },
      "source": [
        "train_df.head()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>posting_id</th>\n",
              "      <th>image</th>\n",
              "      <th>image_phash</th>\n",
              "      <th>title</th>\n",
              "      <th>label_group</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>train_129225211</td>\n",
              "      <td>0000a68812bc7e98c42888dfb1c07da0.jpg</td>\n",
              "      <td>94974f937d4c2433</td>\n",
              "      <td>Paper Bag Victoria Secret</td>\n",
              "      <td>249114794</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>train_3386243561</td>\n",
              "      <td>00039780dfc94d01db8676fe789ecd05.jpg</td>\n",
              "      <td>af3f9460c2838f0f</td>\n",
              "      <td>Double Tape 3M VHB 12 mm x 4,5 m ORIGINAL / DO...</td>\n",
              "      <td>2937985045</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>train_2288590299</td>\n",
              "      <td>000a190fdd715a2a36faed16e2c65df7.jpg</td>\n",
              "      <td>b94cb00ed3e50f78</td>\n",
              "      <td>Maling TTS Canned Pork Luncheon Meat 397 gr</td>\n",
              "      <td>2395904891</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>train_2406599165</td>\n",
              "      <td>00117e4fc239b1b641ff08340b429633.jpg</td>\n",
              "      <td>8514fc58eafea283</td>\n",
              "      <td>Daster Batik Lengan pendek - Motif Acak / Camp...</td>\n",
              "      <td>4093212188</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>train_3369186413</td>\n",
              "      <td>00136d1cf4edede0203f32f05f660588.jpg</td>\n",
              "      <td>a6f319f924ad708c</td>\n",
              "      <td>Nescafe \\xc3\\x89clair Latte 220ml</td>\n",
              "      <td>3648931069</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         posting_id  ... label_group\n",
              "0   train_129225211  ...   249114794\n",
              "1  train_3386243561  ...  2937985045\n",
              "2  train_2288590299  ...  2395904891\n",
              "3  train_2406599165  ...  4093212188\n",
              "4  train_3369186413  ...  3648931069\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "tfOcUljsL0lG",
        "outputId": "0b8e9b48-df1a-413e-ac6e-1503b0efc4d0"
      },
      "source": [
        "class ShopeeDataset(Dataset):\n",
        "\n",
        "    def __init__(self, dataframe, dir_path,transforms):\n",
        "        self.dataframe = dataframe\n",
        "        self.dir_path = dir_path\n",
        "        self.transforms = transforms\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataframe)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        img_info = self.dataframe.iloc[index]\n",
        "        \n",
        "        img = cv2.imread(self.dir_path + '/' + img_info['image'])\n",
        "        label = torch.tensor([img_info['label_group']])\n",
        "\n",
        "        if self.transforms:\n",
        "            augmented = self.transforms(image=img) \n",
        "            img = augmented['image']\n",
        "\n",
        "        return img, label\n",
        "\n",
        "albumentations_transforms = albumentations.Compose([\n",
        "    albumentations.Resize(300, 300, interpolation = cv2.INTER_LANCZOS4), \n",
        "    albumentations.Sharpen(),\n",
        "    albumentations.ColorJitter(brightness=0.1, contrast=0.4, saturation=0, hue=0),\n",
        "    albumentations.ShiftScaleRotate(rotate_limit=180, p=0.5, interpolation = cv2.INTER_LANCZOS4),\n",
        "    albumentations.Normalize(mean=(0, 0, 0), std=(1, 1, 1)),\n",
        "    ToTensorV2() \n",
        "])\n",
        "train_ds = ShopeeDataset(train_df, train_img_path, albumentations_transforms)\n",
        "\n",
        "my_seed(33)\n",
        "\n",
        "train_dl = DataLoader(train_ds, batch_size=4, shuffle=True)\n",
        "# visualize a batch\n",
        "num_samples = 8\n",
        "fig, ax = plt.subplots(1, num_samples, figsize=(25, 10))\n",
        "for i in range(num_samples):\n",
        "    ax[i].imshow((train_ds[32][0]).permute(1, 2, 0))\n",
        "    ax[i].axis('off')\n",
        "#i = iter(train_dl)\n",
        "#plt.figure(figsize=(20, 5))\n",
        "#j = 1\n",
        "#for im in next(i)[0]:\n",
        "#    plt.subplot(1, 4, j)\n",
        "#    j += 1\n",
        "#    plt.imshow(im.permute(1, 2, 0))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-66561c5bf35d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m albumentations_transforms = albumentations.Compose([\n\u001b[1;32m     24\u001b[0m     \u001b[0malbumentations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mINTER_LANCZOS4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0malbumentations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSharpen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0malbumentations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mColorJitter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbrightness\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontrast\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaturation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0malbumentations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mShiftScaleRotate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrotate_limit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m180\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mINTER_LANCZOS4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'albumentations' has no attribute 'Sharpen'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1_gPyhZzL_M7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}